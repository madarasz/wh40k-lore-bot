# Story 1.8: Chroma Vector Database Integration

## Status
Ready

## Story
**As a** developer,
**I want** to store chunk embeddings in Chroma,
**so that** I can perform fast similarity searches.

## Acceptance Criteria
1. `src/rag/vector_store.py` created with `ChromaVectorStore` class
2. Chroma persistent client initialized:
   - Storage path: `data/chroma-db/`
   - Collection name: `wh40k-lore`
3. Collection metadata schema:
   - `article_title`: string
   - `section_path`: string
   - `chunk_index`: int
   - `faction`: string (optional, for filtering)
   - `era`: string (optional, for filtering)
   - `spoiler_flag`: bool
   - `content_type`: string
4. `add_chunks(chunks: List[Chunk], embeddings: List[np.ndarray])` method
5. Batch insertion: 1000 chunks per batch (Chroma performance)
6. `query(query_embedding: np.ndarray, n_results: int, filters: Dict) -> List[Chunk]` method
7. Metadata filtering support:
   - Filter by faction: `{"faction": "Space Marines"}`
   - Filter by era: `{"era": "Horus Heresy"}`
   - Exclude spoilers: `{"spoiler_flag": False}`
8. Distance metric: Cosine similarity
9. Unit tests with mock Chroma client
10. Integration test: Insert 100 chunks, query with filters

## Tasks / Subtasks

- [ ] Create ChromaVectorStore class (AC: 1, 2)
  - [ ] Create src/rag/vector_store.py
  - [ ] Implement ChromaVectorStore class
  - [ ] Initialize Chroma PersistentClient with path "data/chroma-db/"
  - [ ] Create or get collection "wh40k-lore"
  - [ ] Set distance metric to cosine similarity
  - [ ] Add structlog logger instance
  - [ ] Add type hints and docstring
- [ ] Define collection metadata schema (AC: 3)
  - [ ] Document metadata fields in docstring
  - [ ] Define metadata typing (TypedDict)
  - [ ] Ensure all required fields present
  - [ ] Handle optional fields (faction, era)
  - [ ] Validate metadata before insertion
- [ ] Implement chunk insertion (AC: 4, 5)
  - [ ] Implement add_chunks(chunks: List[Chunk], embeddings: List[np.ndarray])
  - [ ] Validate chunks and embeddings have same length
  - [ ] Generate unique IDs for each chunk (UUID)
  - [ ] Convert Chunk objects to metadata dicts
  - [ ] Batch insertions: 1000 chunks per batch
  - [ ] Call collection.add(ids, embeddings, metadatas, documents)
  - [ ] Log insertion progress
  - [ ] Handle insertion errors gracefully
- [ ] Implement query method (AC: 6, 8)
  - [ ] Implement query(query_embedding, n_results, filters=None) -> List[Chunk]
  - [ ] Call collection.query(query_embeddings, n_results, where=filters)
  - [ ] Use cosine similarity for distance metric
  - [ ] Convert results back to Chunk objects
  - [ ] Return list of matching chunks with scores
  - [ ] Handle empty results gracefully
- [ ] Implement metadata filtering (AC: 7)
  - [ ] Support faction filtering: {"faction": "value"}
  - [ ] Support era filtering: {"era": "value"}
  - [ ] Support spoiler filtering: {"spoiler_flag": false}
  - [ ] Support compound filters (AND logic)
  - [ ] Document filter syntax in docstring
  - [ ] Add examples of filter usage
- [ ] Add utility methods
  - [ ] Implement count() -> int (total chunks in collection)
  - [ ] Implement delete_collection() (for testing/reset)
  - [ ] Implement get_by_id(chunk_id: str) -> Optional[Chunk]
  - [ ] Add type hints and docstrings
- [ ] Write unit tests (AC: 9)
  - [ ] Create tests/unit/test_vector_store.py
  - [ ] Mock Chroma client and collection
  - [ ] Test add_chunks with valid data
  - [ ] Test add_chunks with mismatched lengths (error)
  - [ ] Test batch processing (>1000 chunks)
  - [ ] Test query without filters
  - [ ] Test query with faction filter
  - [ ] Test query with era filter
  - [ ] Test query with spoiler filter
  - [ ] Test query with compound filters
  - [ ] Test empty results
- [ ] Write integration test (AC: 10)
  - [ ] Create tests/integration/test_chroma_integration.py
  - [ ] Test with real Chroma database
  - [ ] Insert 100 test chunks with embeddings
  - [ ] Query with various filters
  - [ ] Verify results are relevant
  - [ ] Verify cosine similarity scores
  - [ ] Clean up test database after test
- [ ] Verify all acceptance criteria met
  - [ ] Run unit tests with `poetry run pytest tests/unit/`
  - [ ] Run integration test with `poetry run pytest tests/integration/`
  - [ ] Verify data persists across sessions
  - [ ] Verify filtering works correctly

## Dev Notes

### Previous Story Insights
Story 1.7 completed:
- Embedding generation working
- 1536-dimensional embeddings from OpenAI
- Ready to store in vector database

### Technical Notes
**[Source: docs/epic-1-foundation-data-pipeline.md - Story 1.8]**

- Chroma embedded mode (no server required for MVP)
- Collection persists to disk automatically
- Future: Upgrade to Chroma server for production

### Chroma Setup

```python
import chromadb
from chromadb.config import Settings

# Initialize persistent client
client = chromadb.PersistentClient(path="data/chroma-db/")

# Get or create collection
collection = client.get_or_create_collection(
    name="wh40k-lore",
    metadata={"hnsw:space": "cosine"}  # Cosine similarity
)
```

### Adding Chunks to Chroma

```python
# Batch insertion
collection.add(
    ids=["chunk_1", "chunk_2", ...],
    embeddings=[[0.1, 0.2, ...], [0.3, 0.4, ...], ...],
    metadatas=[
        {
            "article_title": "Blood Angels",
            "section_path": "History > Founding",
            "chunk_index": 0,
            "faction": "Space Marines",
            "era": "Great Crusade",
            "spoiler_flag": False,
            "content_type": "lore"
        },
        ...
    ],
    documents=["chunk text 1", "chunk text 2", ...]
)
```

### Querying with Filters

```python
# Query with metadata filter
results = collection.query(
    query_embeddings=[[0.1, 0.2, ...]],
    n_results=10,
    where={
        "faction": "Space Marines",
        "spoiler_flag": False
    }
)

# Results structure
{
    "ids": [["chunk_1", "chunk_2", ...]],
    "distances": [[0.15, 0.23, ...]],
    "metadatas": [[{...}, {...}, ...]],
    "documents": [["text 1", "text 2", ...]]
}
```

### Filter Syntax

**Simple filter:**
```python
{"faction": "Space Marines"}
```

**Compound filter (AND):**
```python
{
    "faction": "Space Marines",
    "era": "Horus Heresy",
    "spoiler_flag": False
}
```

**Chroma also supports:**
- `$eq`, `$ne` (equal, not equal)
- `$in`, `$nin` (in list, not in list)
- `$gt`, `$gte`, `$lt`, `$lte` (comparisons)
- `$and`, `$or` (logical operators)

### Metadata Schema

```python
from typing import TypedDict, Optional

class ChunkMetadata(TypedDict):
    article_title: str
    section_path: str
    chunk_index: int
    faction: Optional[str]
    era: Optional[str]
    spoiler_flag: bool
    content_type: str
```

### Performance Considerations

**Batch size:**
- Chroma recommends batches of 1000 chunks
- Larger batches may cause memory issues
- Smaller batches increase overhead

**Index building:**
- Chroma builds HNSW index automatically
- Index builds in background
- First query may be slower (index warming)

### Coding Standards Reminders

**[Source: docs/architecture/coding-standards.md]**
- Type hints required for all function signatures
- Docstrings required for all public functions (Google style)
- Use TypedDict for structured metadata
- Handle errors gracefully (database failures)
- Log database operations for debugging

## Dev Agent Record

### Agent Model Used
[To be populated during implementation]

### Debug Log References
[To be populated during implementation]

### Completion Notes List
[To be populated during implementation]

### File List
[To be populated during implementation]

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-26 | 1.0 | Story created from Epic 1 | Bob (Scrum Master) |

## QA Results
[To be populated by QA agent]
