# Story 2.0: BM25 Repository Implementation

## Status
Complete

## Epic
Epic 2: Core RAG Query System

## Dependencies
- Epic 1 must be complete (markdown archives ready, chunks created)
- Existing models: `Chunk` from `src/ingestion/models.py`
- Existing infrastructure: structlog, pathlib

## Story
**As a** developer,
**I want** a BM25 repository that manages keyword-based search index for sparse retrieval,
**so that** the hybrid retrieval service can perform keyword matching alongside vector similarity search.

## Acceptance Criteria

### Core Functionality
1. `BM25Repository` class created in `src/repositories/bm25_repository.py`
2. Index building from chunks:
   - `build_index(chunks: List[Chunk]) -> None` method
   - Tokenizes chunk text using simple whitespace + lowercase tokenization
   - Builds BM25 index using rank-bm25 library (BM25Okapi algorithm)
   - Maintains chunk_id to Chunk mapping for retrieval
3. Search functionality:
   - `search(query: str, top_k: int = 20) -> List[Tuple[Chunk, float]]` method
   - Returns chunks with BM25 scores (higher is better)
   - Supports top-k result limiting
   - Returns empty list if no matches found
4. Index persistence:
   - `save_index(filepath: Path) -> None` method saves index to disk
   - `load_index(filepath: Path) -> None` method loads index from disk
   - Uses pickle for serialization (rank-bm25 index and chunk mapping)
   - Default path: `data/bm25-index/bm25_index.pkl`
5. Update functionality:
   - `update_index(chunks: List[Chunk]) -> None` method
   - Rebuilds index with new chunks (full rebuild, no incremental updates for MVP)
   - Maintains consistency between index and chunk mapping

### Configuration
6. Configuration via environment:
   - `BM25_INDEX_PATH` (default: "data/bm25-index/bm25_index.pkl")
   - `BM25_TOKENIZE_LOWERCASE` (default: False)

### Observability
7. Structured logging:
   - Index build: total chunks, unique tokens, build time
   - Search: query text, results count, search latency
   - Save/load: file path, operation success/failure

### Testing
8. Unit tests covering:
   - Index building with sample chunks
   - Search with various queries (exact match, partial match, no match)
   - Score ordering (highest scores first)
   - Empty chunk list handling
   - Save/load index persistence
   - Update index (rebuild)
   - Tokenization correctness (lowercase, whitespace split)

### CLI Integration (Added Scope)
9. BM25 index building integrated into ingestion pipeline:
   - `poetry run store` command builds BM25 index alongside vector storage
   - `poetry run ingest` automatically creates BM25 index
   - Optional `poetry run build-bm25` standalone command for debugging
   - Step-by-step pipeline includes BM25: chunk ‚Üí build-bm25 ‚Üí embed ‚Üí store

## Tasks / Subtasks

- [x] Task 1: Create BM25Repository class structure (AC: 1)
  - [x] Create `src/repositories/bm25_repository.py`
  - [x] Define `BM25Repository` class
  - [x] Add initialization with configuration loading
  - [x] Add structlog logger instance
  - [x] Add type hints and docstring
  - [x] Import rank-bm25 library (BM25Okapi)

- [x] Task 2: Implement tokenization (AC: 2)
  - [x] Create `_tokenize(text: str) -> List[str]` private method
  - [x] Implement lowercase conversion (configurable)
  - [x] Implement whitespace-based splitting
  - [x] Handle empty strings and None values
  - [x] Log tokenization for debugging

- [x] Task 3: Implement index building (AC: 2)
  - [x] Implement `build_index(chunks: List[Chunk]) -> None`
  - [x] Tokenize all chunk texts
  - [x] Build BM25Okapi index from tokenized corpus
  - [x] Create chunk_id to Chunk mapping (dict)
  - [x] Store chunk order for result retrieval
  - [x] Log index build metrics (chunk count, build time)
  - [x] Handle edge case: empty chunks list

- [x] Task 4: Implement search functionality (AC: 3)
  - [x] Implement `search(query: str, top_k: int = 20) -> List[Tuple[Chunk, float]]`
  - [x] Tokenize query using same `_tokenize()` method
  - [x] Call BM25Okapi.get_scores() to get all scores
  - [x] Sort chunks by score (descending)
  - [x] Return top-k chunks with scores
  - [x] Handle empty query gracefully
  - [x] Handle case when index not built
  - [x] Log search metrics (query, results count, latency)

- [x] Task 5: Implement index persistence (AC: 4)
  - [x] Implement `save_index(filepath: Path) -> None`
  - [x] Create directory if not exists
  - [x] Serialize BM25 index and chunk mapping using pickle
  - [x] Handle file write errors
  - [x] Log save operation (path, success/failure)
  - [x] Implement `load_index(filepath: Path) -> None`
  - [x] Deserialize BM25 index and chunk mapping
  - [x] Validate loaded data integrity
  - [x] Handle file not found error
  - [x] Log load operation (path, success/failure)

- [x] Task 6: Implement update functionality (AC: 5)
  - [x] Implement `update_index(chunks: List[Chunk]) -> None`
  - [x] Call `build_index()` internally (full rebuild)
  - [x] Log update operation
  - [x] Document that this is full rebuild (no incremental for MVP)

- [x] Task 7: Add utility methods
  - [x] Implement `get_index_stats() -> dict` (chunk count, token count, etc.)
  - [x] Implement `is_index_built() -> bool` (check if index exists)
  - [x] Add docstrings for all methods

- [x] Task 8: Write unit tests (AC: 8)
  - [x] Create `tests/unit/test_bm25_repository.py`
  - [x] Test index building with 5 sample chunks
  - [x] Test search: exact keyword match (high score)
  - [x] Test search: partial keyword match (medium score)
  - [x] Test search: no keyword match (low/zero score)
  - [x] Test search: score ordering (descending)
  - [x] Test search: top_k limiting (return only top 3 of 5)
  - [x] Test search: empty index (before build)
  - [x] Test search: empty query string
  - [x] Test save and load index (roundtrip)
  - [x] Test update index (rebuilds correctly)
  - [x] Test tokenization (lowercase, whitespace)
  - [x] Test empty chunks list handling

- [x] Task 9: Integration test
  - [x] Create `tests/integration/test_bm25_integration.py`
  - [x] Use real Chunk objects from sample markdown
  - [x] Build index with 50+ chunks
  - [x] Perform queries for proper nouns (e.g., "Guilliman", "Ultramarines")
  - [x] Verify BM25 ranks exact matches higher than partial matches
  - [x] Test persistence (save, load, search again)
  - [x] Clean up test files after test

- [x] Task 10: Integrate BM25 into `poetry run store` command
  - [x] Update `src/cli/store.py` to build BM25 index alongside ChromaDB storage
  - [x] Load chunks from embeddings JSON (chunks data is available)
  - [x] Create BM25Repository instance
  - [x] Call `build_index()` with chunks
  - [x] Call `save_index()` to persist to `data/bm25-index/bm25_index.pkl`
  - [x] Add logging for BM25 index build progress
  - [x] Handle errors gracefully (log but don't fail the whole store operation)
  - [x] Update `store` command help text to mention BM25 indexing

- [x] Task 11: Add standalone `poetry run build-bm25` CLI command (optional/debugging)
  - [x] Create `src/cli/build_bm25.py` for standalone BM25 index building
  - [x] Accept chunks JSON file as input (from `poetry run chunk` output)
  - [x] Load chunks from JSON, convert to Chunk objects
  - [x] Build BM25 index using BM25Repository
  - [x] Save index to configured path
  - [x] Add to pyproject.toml scripts section
  - [x] Add comprehensive logging and progress indicators
  - [x] Write unit tests for CLI command

- [x] Task 12: Update `poetry run ingest` to include BM25
  - [x] Integrated BM25 index building into IngestionPipeline
  - [x] Added `_all_chunks` collection during batch processing
  - [x] Added `_build_bm25_index()` method to pipeline
  - [x] Set `wiki_page_id` on chunks before BM25 indexing
  - [x] Fixed chunk ID format to use `{wiki_page_id}_{chunk_index}` (consistent with vector store)
  - [x] Tested full pipeline: `poetry run ingest` ‚Üí BM25 index created successfully

- [x] Task 13: Optimize BM25 index storage (Completed)
  - [x] **Issue Identified**: Current implementation stores redundant data in pickle file
    - Stores full Chunk objects (~1.5 MB of 1.9 MB file)
    - Stores chunk_mapping dict (never used for lookups)
    - Duplicates data already available in ChromaDB
  - [x] **Implemented Optimization**:
    - Only store BM25Okapi index and ordered chunk_ids list
    - Reduce file size from ~1.9 MB to ~300-400 KB (5x reduction)
    - Eliminate data duplication (single source of truth in ChromaDB)
    - Changed pickle format from:
      ```python
      {
          "bm25": BM25Okapi,
          "chunks": list[Chunk],           # REMOVED - redundant
          "chunk_mapping": dict[str, Chunk]  # REMOVED - redundant
      }
      ```
    - To:
      ```python
      {
          "bm25": BM25Okapi,
          "chunk_ids": list[str],  # Ordered list to map BM25 indices ‚Üí chunk IDs
          "tokenize_lowercase": bool  # Save config for consistency
      }
      ```
  - [x] Updated `search()` method to return `List[Tuple[str, float]]` (chunk_id, score)
  - [x] Updated `save_index()` to store only BM25 + chunk_ids + config
  - [x] Updated `load_index()` with backward compatibility for old format
  - [x] Updated all unit tests (24 tests) for new search() signature
  - [x] Updated all integration tests (9 tests) with chunk lookup helper
  - [x] Backward compatibility: Old format files auto-migrate on load
  - [x] **Impact**: Breaking change for existing search() interface (handled in tests)
  - [x] **Result**: All 43 tests passing, 84% coverage on BM25Repository

## Dev Notes

### Previous Story Insights
No previous stories in Epic 2. This is the first story and establishes the BM25 repository pattern for keyword-based retrieval.

### Architecture Context

**BM25 Repository Specification**
[Source: docs/architecture.md#13-bm25-repository]

**Responsibility:** Manages BM25 keyword index for sparse retrieval.

**Key Interfaces:**
- `search(query: str, top_k: int) -> List[Tuple[chunk_id, score]]`
- `build_index(chunks: List[WikiChunk]) -> None`
- `update_index(chunks: List[WikiChunk]) -> None`

**Dependencies:** rank-bm25 library

**Note:** The architecture document references `WikiChunk` but the actual model is `Chunk` from `src/ingestion/models.py` (Epic 1 implementation).

### Tech Stack
[Source: docs/architecture/tech-stack.md]

- **Library:** rank-bm25 version 0.2.2
- **Algorithm:** BM25Okapi (standard BM25 algorithm implementation)
- **Purpose:** Sparse keyword retrieval for hybrid search
- **Rationale:** Pure Python, simple, proven for hybrid search, no external dependencies

### Data Models
[Source: src/ingestion/models.py]

**Chunk Dataclass:**
```python
@dataclass
class Chunk:
    chunk_text: str          # Text content to index
    article_title: str       # Source article
    section_path: str        # Hierarchical section
    chunk_index: int         # Index within article
    links: list[str]         # Internal wiki links
    wiki_page_id: str | None # Wiki page ID for chunk ID generation (added)
```

The BM25 index will:
- Index the `chunk_text` field for keyword search
- Store full Chunk objects for retrieval
- Use chunk hash or generated UUID as chunk_id

### File Locations
[Source: docs/architecture/source-tree.md]

**Repository location:** `src/repositories/bm25_repository.py`

**Index storage:** `data/bm25-index/` (gitignored)

**Test locations:**
- Unit tests: `tests/unit/test_bm25_repository.py`
- Integration tests: `tests/integration/test_bm25_integration.py`

### Project Structure Notes

The repository follows the established pattern from `IngestionProgressRepository`:
- Dependency injection via `__init__()` (though BM25 repository is stateful, not session-based)
- Type hints required for all methods
- Structured logging using structlog
- Docstrings in Google style

### Technical Constraints
[Source: docs/architecture/coding-standards.md]

**Critical Rules:**
1. Never use `print()` - use structlog logger
2. Use pathlib for file operations, not os.path
3. Type hints required for all function signatures
4. Imports: stdlib ‚Üí third-party ‚Üí local (absolute imports only)

**Tokenization Strategy:**
- MVP: Simple whitespace + lowercase tokenization
- Rationale: rank-bm25 library is lightweight and doesn't include advanced tokenization
- Future: Consider nltk or spaCy tokenizers if needed for better recall

**BM25 Algorithm Details:**
[Source: docs/rag-architecture-research-report.md]

- BM25Okapi is the standard implementation
- Handles term frequency (TF) and inverse document frequency (IDF)
- Effective for proper noun matching (character names, faction names, planet names)
- Fast: <10ms search latency for 100K chunks

**Why BM25 for WH40K:**
[Source: docs/rag-architecture-research-report.md#section-4-hybrid-retrieval]

WH40K lore has extensive proper nouns:
- Character names: "Roboute Guilliman", "Horus Lupercal"
- Faction names: "Ultramarines", "Death Guard"
- Planet names: "Terra", "Macragge"
- Event names: "Horus Heresy", "Battle of Calth"

BM25 excels at exact keyword matching for these entities where vector search may struggle with rare tokens.

### Security Considerations
[Source: docs/architecture/coding-standards.md]

- Use pickle only for trusted data (self-generated BM25 index)
- Validate file paths to prevent directory traversal
- Handle file I/O errors gracefully (disk full, permissions)

### Performance Considerations
[Source: docs/rag-architecture-research-report.md]

**BM25 Index Size:**
- Approximately 1.2-1.5x text corpus size
- For 10K articles, 100K chunks ‚Üí ~200MB index size
- In-memory index for fast search (<10ms latency)

**Search Latency Target:**
- Target: <10ms for BM25 search
- Typical: 5-10ms for 100K chunks
- Well within hybrid retrieval budget (<100ms total)

### Environment Configuration

**Required .env variables:**
```bash
# BM25 Index Configuration
BM25_INDEX_PATH=data/bm25-index/bm25_index.pkl  # Index file path
BM25_TOKENIZE_LOWERCASE=false                     # Lowercase tokens (default: false)
```

### Testing

#### Testing Standards
[Source: docs/architecture/tech-stack.md]

- **Framework:** pytest 8.0+
- **Coverage:** pytest-cov 4.1+ (target: >70%)
- **Mocking:** pytest-mock 3.12+
- **Async:** pytest-asyncio 0.23+ (not needed for BM25Repository, it's synchronous)

#### Test Strategy

**Unit Tests:**
- Mock file I/O (save/load operations)
- Use small sample datasets (5-10 chunks)
- Test edge cases: empty input, missing index, invalid queries
- Verify tokenization correctness
- Verify score ordering (descending)

**Integration Tests:**
- Use real Chunk objects from test markdown files
- Build index with 50+ chunks (representative size)
- Test real-world queries: proper nouns, multi-word phrases
- Verify persistence: save ‚Üí load ‚Üí search consistency
- Clean up test files in teardown

**Test Data Location:**
[Source: docs/architecture/source-tree.md]
- `tests/fixtures/` for sample markdown and chunks

### Requirements Traceability
[Source: docs/prd/requirements.md]

- **FR7:** System SHALL build and maintain a BM25 index for keyword-based retrieval alongside vector search
  - Satisfied by: `build_index()`, `update_index()`, `save_index()`, `load_index()`

- **FR9:** System SHALL perform hybrid retrieval combining vector similarity search and BM25 keyword matching using Reciprocal Rank Fusion
  - Prerequisite: This story provides BM25 search capability
  - Integration: Story 2.1 (Hybrid Retrieval Service) will consume BM25Repository

### Dependencies and Integration Points

**Used by (Story 2.1):**
- HybridRetrievalService will call `BM25Repository.search(query_text, top_k=20)`
- Expects: List[Tuple[Chunk, float]] return type
- Parallel execution: BM25 search runs concurrently with vector search

**Consumes:**
- Chunk model from `src/ingestion/models.py` (Epic 1)
- rank-bm25 library (to be installed via poetry)

**Produces:**
- BM25 index file: `data/bm25-index/bm25_index.pkl`
- Search results: ranked chunks with BM25 scores

### Implementation Notes

**rank-bm25 Library Usage:**
```python
from rank_bm25 import BM25Okapi

# Tokenization
tokenized_corpus = [doc.lower().split() for doc in corpus]

# Index building
bm25 = BM25Okapi(tokenized_corpus)

# Search
tokenized_query = query.lower().split()
scores = bm25.get_scores(tokenized_query)
```

**Chunk ID Strategy:**
The repository uses the same chunk ID format as the vector store:
1. Generate chunk IDs using `generate_chunk_id(wiki_page_id, chunk_index)` ‚Üí `f"{wiki_page_id}_{chunk_index}"`
2. Maintain mapping: `chunk_id -> Chunk object` (stored in pickle file)
3. Use list index during BM25 scoring, map back to Chunk via stored list

**Note:** The chunk_mapping and chunks list in the pickle file are redundant with ChromaDB data. See Task 13 for optimization opportunity.

**Why Pickle for Persistence:**
- BM25Okapi is not JSON-serializable
- Pickle preserves Python object state
- Fast serialization/deserialization
- Acceptable for self-generated trusted data
- Future: Consider joblib for larger indexes

### Known Limitations (MVP Scope)

1. **Full Rebuild Only:** No incremental index updates (acceptable for MVP)
2. **Simple Tokenization:** Whitespace + lowercase (no stemming, no stopwords)
3. **No Language Detection:** Assumes mixed Hungarian/English corpus works with simple tokenization
4. **In-Memory Index:** Full index loaded in memory (acceptable for <200MB)
5. **No Sharding:** Single index file (acceptable for single-server deployment)

### Future Enhancements (Out of Scope)

- Incremental index updates (append-only)
- Advanced tokenization (stemming, lemmatization)
- Multi-language tokenization (Hungarian-specific)
- Index sharding for very large corpora (>1M chunks)
- Compressed index storage (joblib, gzip)

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-05 | 1.0 | Initial story creation | Scrum Master (Bob) |

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)

### Debug Log References
None - No blocking issues encountered during development

### Completion Notes List

**Phase 1 - Core Repository (Completed):**
- ‚úÖ Tasks 1-9: BM25Repository fully implemented with all core functionality (build, search, persist, update)
- ‚úÖ Comprehensive test coverage: 24 unit tests + 9 integration tests (33 total), all passing
- ‚úÖ Code coverage: 92% for [bm25_repository.py](src/repositories/bm25_repository.py)
- ‚úÖ Linting and type checking pass cleanly (ruff + mypy)
- ‚úÖ All original acceptance criteria met
- üìù **Technical Details:** Implemented simple whitespace+lowercase tokenization as specified. BM25Okapi algorithm from rank-bm25 library used. Pickle serialization for index persistence.

**Phase 2 - CLI Integration (Added Scope - Completed):**
- ‚úÖ **Tasks 10-12 Completed:** BM25 indexing fully integrated into ingestion pipeline
- üéØ **Integration Points:**
  - Task 10: ‚úÖ Integrated into `poetry run store` command - builds BM25 index automatically
  - Task 11: ‚úÖ Added standalone `poetry run build-bm25` command for debugging
  - Task 12: ‚úÖ Integrated into `poetry run ingest` pipeline - builds BM25 index after vector storage
- üìã **Updated Pipeline Flow:**
  ```
  poetry run store <embeddings.json>  ‚Üí Stores vectors + builds BM25 index
  poetry run build-bm25 <chunks.json> ‚Üí Standalone BM25 index building (debugging)
  poetry run ingest                   ‚Üí Full pipeline (includes BM25 via IngestionPipeline)
  ```
- üìù **Technical Implementation:**
  - **store.py**: Added `_convert_to_chunks()` helper, BM25 indexing after vector storage
    - Fixed early return when no vector changes detected but BM25 index missing
    - Wrapped vector storage in conditional to skip when no chunks to store
  - **build_bm25.py**: Standalone CLI with `_load_chunks_from_json()` and `_build_and_save_index()` helpers
  - **pipeline.py**: Added `_all_chunks` collection and `_build_bm25_index()` method
    - Collects chunks during batch processing (after successful vector storage)
    - Builds BM25 index at end of ingestion run
    - Sets `wiki_page_id` on chunks for proper chunk ID generation
  - **models.py**: Added `wiki_page_id: str | None` field to Chunk dataclass
  - **bm25_repository.py**: Updated chunk ID generation to use `{wiki_page_id}_{chunk_index}` format
    - Imported `generate_chunk_id()` from vector_store for consistency
    - Added fallback for chunks without wiki_page_id (backwards compatibility)
  - **Error Handling**: BM25 failures don't abort vector storage (graceful degradation)
  - **Logging**: Comprehensive structured logging for BM25 operations
  - **Test Coverage**: 10 new CLI tests, all passing with 100% coverage for build_bm25.py

**Phase 3 - Chunk ID Format Fix (Completed):**
- ‚úÖ Fixed chunk ID format inconsistency
- üîß **Issue:** BM25 was using `{article_title}:{chunk_index}` while vector store uses `{wiki_page_id}_{chunk_index}`
- ‚úÖ **Resolution:**
  - Updated Chunk dataclass to include optional `wiki_page_id` field
  - Updated BM25Repository to use `generate_chunk_id()` function from vector_store
  - Updated all CLI commands to set `wiki_page_id` when creating Chunk objects
  - Updated IngestionPipeline to set `wiki_page_id` before collecting chunks
- ‚úÖ **Verification:** All 493 test chunks now use correct format (e.g., `16481_0` instead of `Blood Angels:0`)

**Phase 4 - Storage Optimization (Task 13 - Completed):**
- ‚úÖ **Optimization Implemented:** BM25 pickle file no longer stores redundant data
  - Old file: 1.9 MB (493 chunks with full Chunk objects)
  - New file: ~300-400 KB (5x reduction - only BM25 index + chunk IDs)
  - Eliminated data duplication with ChromaDB
  - Single source of truth maintained (ChromaDB)
- üîß **Technical Changes:**
  - Updated pickle format to store only: BM25Okapi + chunk_ids + tokenize_lowercase config
  - Changed `search()` signature: Returns `List[Tuple[str, float]]` (chunk_id, score) instead of `List[Tuple[Chunk, float]]`
  - Instance variables: Replaced `self.chunks` and `self.chunk_mapping` with `self.chunk_ids`
  - Added tokenize_lowercase to pickle for consistency across save/load cycles
- ‚úÖ **Backward Compatibility:**
  - `load_index()` auto-detects old vs new format
  - Old format files automatically migrate chunk data to chunk_ids on load
  - Warning logged when loading old format files
- ‚úÖ **Breaking Changes Handled:**
  - Updated 24 unit tests to work with chunk_id results
  - Updated 9 integration tests with chunk lookup helper
  - Added `build_chunk_lookup()` helper for testing
  - All CLI tests (10) pass without modification (don't use search())
- ‚úÖ **Validation:**
  - All 43 tests passing (24 unit + 9 integration + 10 CLI)
  - Code coverage: 84% for [bm25_repository.py](src/repositories/bm25_repository.py)
  - Linting and type checking pass cleanly (ruff + mypy)
- üìù **Bug Fixed:** Discovered and fixed tokenization config not being saved/loaded, causing search inconsistency after load

### File List
**Created:**
- [src/repositories/bm25_repository.py](src/repositories/bm25_repository.py) - 341 lines - BM25 keyword search repository
- [tests/unit/test_bm25_repository.py](tests/unit/test_bm25_repository.py) - 323 lines - Comprehensive unit tests (24 tests)
- [tests/integration/test_bm25_integration.py](tests/integration/test_bm25_integration.py) - 452 lines - Integration tests with realistic WH40K data (9 tests)
- [src/cli/build_bm25.py](src/cli/build_bm25.py) - 159 lines - Standalone BM25 index building CLI command
- [tests/unit/test_cli_build_bm25.py](tests/unit/test_cli_build_bm25.py) - 276 lines - Unit tests for build-bm25 CLI (10 tests)

**Modified (Task 13 - Storage Optimization):**
- [src/repositories/bm25_repository.py](src/repositories/bm25_repository.py) - Optimized to store only chunk_ids instead of full Chunk objects; updated search() to return chunk IDs
- [tests/unit/test_bm25_repository.py](tests/unit/test_bm25_repository.py) - Updated all 24 tests to work with chunk_id results
- [tests/integration/test_bm25_integration.py](tests/integration/test_bm25_integration.py) - Updated all 9 tests with chunk lookup helper

**Modified (Earlier Phases):**
- [src/cli/store.py](src/cli/store.py) - Added BM25 indexing integration (imports, helper function, BM25 build logic, early return fix)
- [src/ingestion/pipeline.py](src/ingestion/pipeline.py) - Added BM25 index building to ingestion pipeline
- [src/ingestion/models.py](src/ingestion/models.py) - Added `wiki_page_id` field to Chunk dataclass
- [pyproject.toml](pyproject.toml) - Added `build-bm25` script entry

**Total:** 5 new files, 8 modified files (3 from Task 13), ~2,000 lines of code and tests

## QA Results
_To be filled by QA Agent_
